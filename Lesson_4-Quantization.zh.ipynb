{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:18.452945Z",
     "start_time": "2025-03-10T08:33:15.543636Z"
    }
   },
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "from helpers import generate"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.329274Z",
     "start_time": "2025-03-10T08:33:18.456025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ],
   "id": "b6f2018bd9204fd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.403102Z",
     "start_time": "2025-03-10T08:33:49.400910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define PAD token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# pad on the left so we can append new tokens on the right\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\""
   ],
   "id": "8d67d28f65efc477",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.407379Z",
     "start_time": "2025-03-10T08:33:49.405709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fix dtype post quantization to \"pretend\" to be fp32\n",
    "def get_float32_dtype(self):\n",
    "    return torch.float32\n",
    "GPT2Model.dtype = property(get_float32_dtype)\n"
   ],
   "id": "27403c3731e23f35",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.417185Z",
     "start_time": "2025-03-10T08:33:49.413837Z"
    }
   },
   "cell_type": "code",
   "source": "model.get_memory_footprint()",
   "id": "89e42f6e98908db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510342192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.425988Z",
     "start_time": "2025-03-10T08:33:49.423754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def quantize(t):\n",
    "    # obtain range of values in the tensor to map between 0 and 255\n",
    "    min_val, max_val = t.min(), t.max()\n",
    "\n",
    "    # determine the \"zero-point\", or value in the tensor to map to 0\n",
    "    scale = (max_val - min_val) / 255\n",
    "    zero_point = min_val\n",
    "\n",
    "    # quantize and clamp to ensure we're in [0, 255]\n",
    "    t_quant = (t - zero_point) / scale\n",
    "    t_quant = torch.clamp(t_quant, min=0, max=255)\n",
    "\n",
    "    # keep track of scale and zero_point for reversing quantization\n",
    "    state = (scale, zero_point)\n",
    "\n",
    "    # cast to uint8 and return\n",
    "    t_quant = t_quant.type(torch.uint8)\n",
    "    return t_quant, state"
   ],
   "id": "480893e0ba07aa16",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.452537Z",
     "start_time": "2025-03-10T08:33:49.437176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t = model.transformer.h[0].attn.c_attn.weight.data\n",
    "print(t, t.shape)"
   ],
   "id": "1ae4aef6b3381678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4738, -0.2614, -0.0978,  ...,  0.0513, -0.0584,  0.0250],\n",
      "        [ 0.0874,  0.1473,  0.2387,  ..., -0.0525, -0.0113, -0.0156],\n",
      "        [ 0.0039,  0.0695,  0.3668,  ...,  0.1143,  0.0363, -0.0318],\n",
      "        ...,\n",
      "        [-0.2592, -0.0164,  0.1991,  ...,  0.0095, -0.0516,  0.0319],\n",
      "        [ 0.1517,  0.2170,  0.1043,  ...,  0.0293, -0.0429, -0.0475],\n",
      "        [-0.4100, -0.1924, -0.2400,  ..., -0.0046,  0.0070,  0.0198]]) torch.Size([768, 2304])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.472794Z",
     "start_time": "2025-03-10T08:33:49.459356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_q, state = quantize(t)\n",
    "print(t_q, t_q.min(), t_q.max())"
   ],
   "id": "bab8367888de74c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[107, 116, 124,  ..., 130, 125, 129],\n",
      "        [132, 135, 139,  ..., 126, 128, 127],\n",
      "        [128, 131, 145,  ..., 133, 130, 127],\n",
      "        ...,\n",
      "        [116, 127, 137,  ..., 129, 126, 130],\n",
      "        [135, 138, 133,  ..., 129, 126, 126],\n",
      "        [110, 119, 117,  ..., 128, 128, 129]], dtype=torch.uint8) tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.483160Z",
     "start_time": "2025-03-10T08:33:49.481186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dequantize(t, state):\n",
    "    scale, zero_point = state\n",
    "    return t.to(torch.float32) * scale + zero_point"
   ],
   "id": "b6e12389320d11b6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.496131Z",
     "start_time": "2025-03-10T08:33:49.490988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_rev = dequantize(t_q, state)\n",
    "print(t_rev)"
   ],
   "id": "10432bfbfe285c7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4774, -0.2783, -0.1014,  ...,  0.0313, -0.0793,  0.0092],\n",
      "        [ 0.0755,  0.1419,  0.2303,  ..., -0.0572, -0.0129, -0.0351],\n",
      "        [-0.0129,  0.0534,  0.3630,  ...,  0.0976,  0.0313, -0.0351],\n",
      "        ...,\n",
      "        [-0.2783, -0.0351,  0.1861,  ...,  0.0092, -0.0572,  0.0313],\n",
      "        [ 0.1419,  0.2082,  0.0976,  ...,  0.0092, -0.0572, -0.0572],\n",
      "        [-0.4110, -0.2120, -0.2562,  ..., -0.0129, -0.0129,  0.0092]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:49.514713Z",
     "start_time": "2025-03-10T08:33:49.510359Z"
    }
   },
   "cell_type": "code",
   "source": "torch.abs(t - t_rev)",
   "id": "6782ff852dc41dee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0035, 0.0170, 0.0036,  ..., 0.0200, 0.0209, 0.0158],\n",
       "        [0.0119, 0.0055, 0.0084,  ..., 0.0046, 0.0017, 0.0195],\n",
       "        [0.0168, 0.0161, 0.0038,  ..., 0.0167, 0.0050, 0.0032],\n",
       "        ...,\n",
       "        [0.0191, 0.0187, 0.0131,  ..., 0.0004, 0.0056, 0.0006],\n",
       "        [0.0098, 0.0088, 0.0067,  ..., 0.0202, 0.0143, 0.0097],\n",
       "        [0.0010, 0.0196, 0.0162,  ..., 0.0084, 0.0199, 0.0107]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:33:50.402813Z",
     "start_time": "2025-03-10T08:33:50.246277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_expected = generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    [(\"The quick brown fox jumped over the\", 10)]\n",
    ")[0]\n",
    "response_expected"
   ],
   "id": "e1e49eb003e6459c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m response_expected \u001B[38;5;241m=\u001B[39m generate(\n\u001B[1;32m      2\u001B[0m     model,\n\u001B[1;32m      3\u001B[0m     tokenizer,\n\u001B[1;32m      4\u001B[0m     [(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe quick brown fox jumped over the\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m10\u001B[39m)]\n\u001B[1;32m      5\u001B[0m )[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      6\u001B[0m response_expected\n",
      "\u001B[0;31mNameError\u001B[0m: name 'generate' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:34:04.743857Z",
     "start_time": "2025-03-10T08:34:04.738577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def quantize_model(model):\n",
    "    states = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "        param.data, state = quantize(param.data)\n",
    "        states[name] = state\n",
    "    return model, states\n",
    "\n",
    "\n"
   ],
   "id": "ae67fd6ff350201c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:34:06.418637Z",
     "start_time": "2025-03-10T08:34:06.001382Z"
    }
   },
   "cell_type": "code",
   "source": "quant_model, states = quantize_model(model)",
   "id": "1f93a1df7674a129",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:34:06.889796Z",
     "start_time": "2025-03-10T08:34:06.885153Z"
    }
   },
   "cell_type": "code",
   "source": "quant_model.get_memory_footprint()",
   "id": "23047bbb49b5d2a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137022768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:45:14.321661Z",
     "start_time": "2025-03-10T08:45:14.279029Z"
    }
   },
   "cell_type": "code",
   "source": "states",
   "id": "b853bf34ff431527",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer.wte.weight': (tensor(0.0120), tensor(-1.2698)),\n",
       " 'transformer.wpe.weight': (tensor(0.0337), tensor(-4.5381)),\n",
       " 'transformer.h.0.ln_1.weight': (tensor(0.0008), tensor(0.0419)),\n",
       " 'transformer.h.0.ln_1.bias': (tensor(0.0018), tensor(-0.2589)),\n",
       " 'transformer.h.0.attn.c_attn.weight': (tensor(0.0221), tensor(-2.8436)),\n",
       " 'transformer.h.0.attn.c_attn.bias': (tensor(0.0099), tensor(-1.3371)),\n",
       " 'transformer.h.0.attn.c_proj.weight': (tensor(0.0250), tensor(-3.3171)),\n",
       " 'transformer.h.0.attn.c_proj.bias': (tensor(0.0185), tensor(-2.6844)),\n",
       " 'transformer.h.0.ln_2.weight': (tensor(0.0057), tensor(0.0453)),\n",
       " 'transformer.h.0.ln_2.bias': (tensor(0.0055), tensor(-0.6648)),\n",
       " 'transformer.h.0.mlp.c_fc.weight': (tensor(0.0271), tensor(-2.3131)),\n",
       " 'transformer.h.0.mlp.c_fc.bias': (tensor(0.0042), tensor(-0.7462)),\n",
       " 'transformer.h.0.mlp.c_proj.weight': (tensor(0.0479), tensor(-6.1433)),\n",
       " 'transformer.h.0.mlp.c_proj.bias': (tensor(0.0098), tensor(-1.0288)),\n",
       " 'transformer.h.1.ln_1.weight': (tensor(0.0023), tensor(0.0725)),\n",
       " 'transformer.h.1.ln_1.bias': (tensor(0.0047), tensor(-0.6645)),\n",
       " 'transformer.h.1.attn.c_attn.weight': (tensor(0.0091), tensor(-1.0771)),\n",
       " 'transformer.h.1.attn.c_attn.bias': (tensor(0.0147), tensor(-1.8151)),\n",
       " 'transformer.h.1.attn.c_proj.weight': (tensor(0.0342), tensor(-4.7262)),\n",
       " 'transformer.h.1.attn.c_proj.bias': (tensor(0.0070), tensor(-0.5346)),\n",
       " 'transformer.h.1.ln_2.weight': (tensor(0.0016), tensor(0.0560)),\n",
       " 'transformer.h.1.ln_2.bias': (tensor(0.0041), tensor(-0.5866)),\n",
       " 'transformer.h.1.mlp.c_fc.weight': (tensor(0.0163), tensor(-1.8728)),\n",
       " 'transformer.h.1.mlp.c_fc.bias': (tensor(0.0036), tensor(-0.6563)),\n",
       " 'transformer.h.1.mlp.c_proj.weight': (tensor(0.0732), tensor(-4.9305)),\n",
       " 'transformer.h.1.mlp.c_proj.bias': (tensor(0.0090), tensor(-0.6991)),\n",
       " 'transformer.h.2.ln_1.weight': (tensor(0.0035), tensor(0.0460)),\n",
       " 'transformer.h.2.ln_1.bias': (tensor(0.0065), tensor(-0.5625)),\n",
       " 'transformer.h.2.attn.c_attn.weight': (tensor(0.0128), tensor(-1.6774)),\n",
       " 'transformer.h.2.attn.c_attn.bias': (tensor(0.0104), tensor(-1.4630)),\n",
       " 'transformer.h.2.attn.c_proj.weight': (tensor(0.0177), tensor(-2.2955)),\n",
       " 'transformer.h.2.attn.c_proj.bias': (tensor(0.0039), tensor(-0.4775)),\n",
       " 'transformer.h.2.ln_2.weight': (tensor(0.0027), tensor(0.0421)),\n",
       " 'transformer.h.2.ln_2.bias': (tensor(0.0040), tensor(-0.6470)),\n",
       " 'transformer.h.2.mlp.c_fc.weight': (tensor(0.0644), tensor(-5.8740)),\n",
       " 'transformer.h.2.mlp.c_fc.bias': (tensor(0.0094), tensor(-0.6598)),\n",
       " 'transformer.h.2.mlp.c_proj.weight': (tensor(0.0704), tensor(-2.8738)),\n",
       " 'transformer.h.2.mlp.c_proj.bias': (tensor(0.0079), tensor(-0.4528)),\n",
       " 'transformer.h.3.ln_1.weight': (tensor(0.0028), tensor(0.0565)),\n",
       " 'transformer.h.3.ln_1.bias': (tensor(0.0085), tensor(-0.4335)),\n",
       " 'transformer.h.3.attn.c_attn.weight': (tensor(0.0142), tensor(-1.7154)),\n",
       " 'transformer.h.3.attn.c_attn.bias': (tensor(0.0054), tensor(-0.6688)),\n",
       " 'transformer.h.3.attn.c_proj.weight': (tensor(0.0130), tensor(-2.0938)),\n",
       " 'transformer.h.3.attn.c_proj.bias': (tensor(0.0061), tensor(-1.0272)),\n",
       " 'transformer.h.3.ln_2.weight': (tensor(0.0046), tensor(-0.0003)),\n",
       " 'transformer.h.3.ln_2.bias': (tensor(0.0034), tensor(-0.4375)),\n",
       " 'transformer.h.3.mlp.c_fc.weight': (tensor(0.0193), tensor(-2.6437)),\n",
       " 'transformer.h.3.mlp.c_fc.bias': (tensor(0.0068), tensor(-1.2262)),\n",
       " 'transformer.h.3.mlp.c_proj.weight': (tensor(0.0833), tensor(-4.1391)),\n",
       " 'transformer.h.3.mlp.c_proj.bias': (tensor(0.0099), tensor(-0.6661)),\n",
       " 'transformer.h.4.ln_1.weight': (tensor(0.0024), tensor(0.0580)),\n",
       " 'transformer.h.4.ln_1.bias': (tensor(0.0082), tensor(-0.5446)),\n",
       " 'transformer.h.4.attn.c_attn.weight': (tensor(0.0252), tensor(-3.3341)),\n",
       " 'transformer.h.4.attn.c_attn.bias': (tensor(0.0210), tensor(-2.6123)),\n",
       " 'transformer.h.4.attn.c_proj.weight': (tensor(0.0144), tensor(-1.8388)),\n",
       " 'transformer.h.4.attn.c_proj.bias': (tensor(0.0045), tensor(-0.6430)),\n",
       " 'transformer.h.4.ln_2.weight': (tensor(0.0042), tensor(0.0701)),\n",
       " 'transformer.h.4.ln_2.bias': (tensor(0.0011), tensor(-0.1421)),\n",
       " 'transformer.h.4.mlp.c_fc.weight': (tensor(0.0164), tensor(-2.1614)),\n",
       " 'transformer.h.4.mlp.c_fc.bias': (tensor(0.0047), tensor(-0.4530)),\n",
       " 'transformer.h.4.mlp.c_proj.weight': (tensor(0.0334), tensor(-3.7426)),\n",
       " 'transformer.h.4.mlp.c_proj.bias': (tensor(0.0088), tensor(-0.6683)),\n",
       " 'transformer.h.5.ln_1.weight': (tensor(0.0027), tensor(0.0864)),\n",
       " 'transformer.h.5.ln_1.bias': (tensor(0.0060), tensor(-0.4506)),\n",
       " 'transformer.h.5.attn.c_attn.weight': (tensor(0.0107), tensor(-1.3924)),\n",
       " 'transformer.h.5.attn.c_attn.bias': (tensor(0.0041), tensor(-0.5594)),\n",
       " 'transformer.h.5.attn.c_proj.weight': (tensor(0.0144), tensor(-1.9833)),\n",
       " 'transformer.h.5.attn.c_proj.bias': (tensor(0.0051), tensor(-0.7030)),\n",
       " 'transformer.h.5.ln_2.weight': (tensor(0.0054), tensor(0.0428)),\n",
       " 'transformer.h.5.ln_2.bias': (tensor(0.0024), tensor(-0.3045)),\n",
       " 'transformer.h.5.mlp.c_fc.weight': (tensor(0.0146), tensor(-1.9646)),\n",
       " 'transformer.h.5.mlp.c_fc.bias': (tensor(0.0043), tensor(-0.4335)),\n",
       " 'transformer.h.5.mlp.c_proj.weight': (tensor(0.0219), tensor(-2.8407)),\n",
       " 'transformer.h.5.mlp.c_proj.bias': (tensor(0.0077), tensor(-0.7120)),\n",
       " 'transformer.h.6.ln_1.weight': (tensor(0.0028), tensor(0.0637)),\n",
       " 'transformer.h.6.ln_1.bias': (tensor(0.0085), tensor(-0.6354)),\n",
       " 'transformer.h.6.attn.c_attn.weight': (tensor(0.0118), tensor(-1.3877)),\n",
       " 'transformer.h.6.attn.c_attn.bias': (tensor(0.0060), tensor(-0.8114)),\n",
       " 'transformer.h.6.attn.c_proj.weight': (tensor(0.0140), tensor(-1.7240)),\n",
       " 'transformer.h.6.attn.c_proj.bias': (tensor(0.0028), tensor(-0.3124)),\n",
       " 'transformer.h.6.ln_2.weight': (tensor(0.0051), tensor(0.0424)),\n",
       " 'transformer.h.6.ln_2.bias': (tensor(0.0028), tensor(-0.2726)),\n",
       " 'transformer.h.6.mlp.c_fc.weight': (tensor(0.0132), tensor(-1.2295)),\n",
       " 'transformer.h.6.mlp.c_fc.bias': (tensor(0.0044), tensor(-0.4310)),\n",
       " 'transformer.h.6.mlp.c_proj.weight': (tensor(0.0197), tensor(-2.2441)),\n",
       " 'transformer.h.6.mlp.c_proj.bias': (tensor(0.0068), tensor(-0.6757)),\n",
       " 'transformer.h.7.ln_1.weight': (tensor(0.0029), tensor(0.0746)),\n",
       " 'transformer.h.7.ln_1.bias': (tensor(0.0078), tensor(-0.7903)),\n",
       " 'transformer.h.7.attn.c_attn.weight': (tensor(0.0137), tensor(-1.6830)),\n",
       " 'transformer.h.7.attn.c_attn.bias': (tensor(0.0058), tensor(-0.7567)),\n",
       " 'transformer.h.7.attn.c_proj.weight': (tensor(0.0163), tensor(-2.2344)),\n",
       " 'transformer.h.7.attn.c_proj.bias': (tensor(0.0038), tensor(-0.4598)),\n",
       " 'transformer.h.7.ln_2.weight': (tensor(0.0050), tensor(0.0149)),\n",
       " 'transformer.h.7.ln_2.bias': (tensor(0.0043), tensor(-0.4666)),\n",
       " 'transformer.h.7.mlp.c_fc.weight': (tensor(0.0082), tensor(-0.8502)),\n",
       " 'transformer.h.7.mlp.c_fc.bias': (tensor(0.0061), tensor(-0.7277)),\n",
       " 'transformer.h.7.mlp.c_proj.weight': (tensor(0.0346), tensor(-4.5328)),\n",
       " 'transformer.h.7.mlp.c_proj.bias': (tensor(0.0075), tensor(-0.7256)),\n",
       " 'transformer.h.8.ln_1.weight': (tensor(0.0034), tensor(0.0657)),\n",
       " 'transformer.h.8.ln_1.bias': (tensor(0.0093), tensor(-0.9212)),\n",
       " 'transformer.h.8.attn.c_attn.weight': (tensor(0.0144), tensor(-1.7242)),\n",
       " 'transformer.h.8.attn.c_attn.bias': (tensor(0.0067), tensor(-0.8690)),\n",
       " 'transformer.h.8.attn.c_proj.weight': (tensor(0.0201), tensor(-2.1775)),\n",
       " 'transformer.h.8.attn.c_proj.bias': (tensor(0.0064), tensor(-0.4676)),\n",
       " 'transformer.h.8.ln_2.weight': (tensor(0.0041), tensor(0.0180)),\n",
       " 'transformer.h.8.ln_2.bias': (tensor(0.0045), tensor(-0.6950)),\n",
       " 'transformer.h.8.mlp.c_fc.weight': (tensor(0.0105), tensor(-1.2222)),\n",
       " 'transformer.h.8.mlp.c_fc.bias': (tensor(0.0060), tensor(-0.5317)),\n",
       " 'transformer.h.8.mlp.c_proj.weight': (tensor(0.0354), tensor(-3.6508)),\n",
       " 'transformer.h.8.mlp.c_proj.bias': (tensor(0.0080), tensor(-0.8268)),\n",
       " 'transformer.h.9.ln_1.weight': (tensor(0.0034), tensor(0.0696)),\n",
       " 'transformer.h.9.ln_1.bias': (tensor(0.0088), tensor(-0.9785)),\n",
       " 'transformer.h.9.attn.c_attn.weight': (tensor(0.0148), tensor(-1.7891)),\n",
       " 'transformer.h.9.attn.c_attn.bias': (tensor(0.0072), tensor(-1.0424)),\n",
       " 'transformer.h.9.attn.c_proj.weight': (tensor(0.0143), tensor(-1.6596)),\n",
       " 'transformer.h.9.attn.c_proj.bias': (tensor(0.0112), tensor(-0.9575)),\n",
       " 'transformer.h.9.ln_2.weight': (tensor(0.0036), tensor(0.0177)),\n",
       " 'transformer.h.9.ln_2.bias': (tensor(0.0042), tensor(-0.5610)),\n",
       " 'transformer.h.9.mlp.c_fc.weight': (tensor(0.0192), tensor(-2.7818)),\n",
       " 'transformer.h.9.mlp.c_fc.bias': (tensor(0.0043), tensor(-0.4776)),\n",
       " 'transformer.h.9.mlp.c_proj.weight': (tensor(0.0406), tensor(-5.4875)),\n",
       " 'transformer.h.9.mlp.c_proj.bias': (tensor(0.0109), tensor(-1.2830)),\n",
       " 'transformer.h.10.ln_1.weight': (tensor(0.0033), tensor(0.0751)),\n",
       " 'transformer.h.10.ln_1.bias': (tensor(0.0068), tensor(-0.6528)),\n",
       " 'transformer.h.10.attn.c_attn.weight': (tensor(0.0145), tensor(-1.8938)),\n",
       " 'transformer.h.10.attn.c_attn.bias': (tensor(0.0066), tensor(-0.9162)),\n",
       " 'transformer.h.10.attn.c_proj.weight': (tensor(0.0325), tensor(-4.0754)),\n",
       " 'transformer.h.10.attn.c_proj.bias': (tensor(0.0268), tensor(-2.9879)),\n",
       " 'transformer.h.10.ln_2.weight': (tensor(0.0042), tensor(0.0201)),\n",
       " 'transformer.h.10.ln_2.bias': (tensor(0.0051), tensor(-0.6005)),\n",
       " 'transformer.h.10.mlp.c_fc.weight': (tensor(0.0184), tensor(-2.5535)),\n",
       " 'transformer.h.10.mlp.c_fc.bias': (tensor(0.0070), tensor(-1.0728)),\n",
       " 'transformer.h.10.mlp.c_proj.weight': (tensor(0.0798), tensor(-11.0504)),\n",
       " 'transformer.h.10.mlp.c_proj.bias': (tensor(0.0095), tensor(-1.0768)),\n",
       " 'transformer.h.11.ln_1.weight': (tensor(0.0033), tensor(0.1061)),\n",
       " 'transformer.h.11.ln_1.bias': (tensor(0.0052), tensor(-0.3304)),\n",
       " 'transformer.h.11.attn.c_attn.weight': (tensor(0.0179), tensor(-2.2638)),\n",
       " 'transformer.h.11.attn.c_attn.bias': (tensor(0.0055), tensor(-0.8046)),\n",
       " 'transformer.h.11.attn.c_proj.weight': (tensor(0.0690), tensor(-8.8818)),\n",
       " 'transformer.h.11.attn.c_proj.bias': (tensor(0.0353), tensor(-5.3729)),\n",
       " 'transformer.h.11.ln_2.weight': (tensor(0.0047), tensor(0.0278)),\n",
       " 'transformer.h.11.ln_2.bias': (tensor(0.0025), tensor(-0.2093)),\n",
       " 'transformer.h.11.mlp.c_fc.weight': (tensor(0.0143), tensor(-1.9649)),\n",
       " 'transformer.h.11.mlp.c_fc.bias': (tensor(0.0068), tensor(-1.2082)),\n",
       " 'transformer.h.11.mlp.c_proj.weight': (tensor(0.0720), tensor(-9.2115)),\n",
       " 'transformer.h.11.mlp.c_proj.bias': (tensor(0.0032), tensor(-0.3835)),\n",
       " 'transformer.ln_f.weight': (tensor(0.0683), tensor(0.0044)),\n",
       " 'transformer.ln_f.bias': (tensor(0.0453), tensor(-4.1918))}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:34:14.535792Z",
     "start_time": "2025-03-10T08:34:14.533006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def size_in_bytes(t):\n",
    "    return t.numel() * t.element_size()\n",
    "\n"
   ],
   "id": "7e59b94a4f9c24c9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:47:00.477948Z",
     "start_time": "2025-03-10T08:47:00.472429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sum([\n",
    "    size_in_bytes(v[0]) + size_in_bytes(v[1])\n",
    "    for v in states.values()\n",
    "])"
   ],
   "id": "294823d36463d261",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:51:01.285090Z",
     "start_time": "2025-03-10T08:51:01.280134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dequantize_model(model, states):\n",
    "    for name, param in model.named_parameters():\n",
    "        param.data = dequantize(param.data, states[name])\n",
    "    return model"
   ],
   "id": "ef3be6d120320c42",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:51:35.652204Z",
     "start_time": "2025-03-10T08:51:35.390587Z"
    }
   },
   "cell_type": "code",
   "source": "dequant_model = dequantize_model(quant_model, states)",
   "id": "1ec99d3b318715e2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:51:53.949888Z",
     "start_time": "2025-03-10T08:51:53.945075Z"
    }
   },
   "cell_type": "code",
   "source": "dequant_model.get_memory_footprint()",
   "id": "fc863b6b4604a8f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510342192"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response_expected = generate(\n",
    "    dequant_model,\n",
    "    tokenizer,\n",
    "    [(\"The quick brown fox jumped over the\", 10)]\n",
    "\n",
    ")[0]\n",
    "response_expected"
   ],
   "id": "3c2a0544900448af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
