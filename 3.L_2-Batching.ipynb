{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T14:20:18.244047Z",
     "start_time": "2025-03-04T14:20:15.516470Z"
    }
   },
   "source": [
    "from time import time_ns\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:20:20.991292Z",
     "start_time": "2025-03-04T14:20:18.249423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ],
   "id": "160492703c0a64f1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:21:53.096364Z",
     "start_time": "2025-03-04T14:21:53.084460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"The quick brown fox jumped over the\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs"
   ],
   "id": "caa1c59dbfda2654",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  464,  2068,  7586, 21831, 11687,   625,   262]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:21:54.246021Z",
     "start_time": "2025-03-04T14:21:54.241558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_token_with_past(inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    last_logits = logits[0, -1, :]\n",
    "    next_token_id = last_logits.argmax()\n",
    "    return next_token_id, outputs.past_key_values"
   ],
   "id": "b59bc4977ed5a48c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:21:55.122881Z",
     "start_time": "2025-03-04T14:21:54.826337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate(inputs, max_tokens):\n",
    "    generated_tokens = []\n",
    "    next_inputs = inputs\n",
    "    for _ in range(max_tokens):\n",
    "        next_token_id, past_key_values = generate_token_with_past(next_inputs)\n",
    "        next_inputs = {\n",
    "            \"input_ids\": next_token_id.reshape((1, 1)),\n",
    "            \"attention_mask\": torch.cat(\n",
    "                [next_inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
    "                dim=1\n",
    "            ),\n",
    "            \"past_key_values\": past_key_values\n",
    "        }\n",
    "\n",
    "        next_token = tokenizer.decode(next_token_id)\n",
    "        generated_tokens.append(next_token)\n",
    "    return  \"\".join(generated_tokens)\n",
    "\n",
    "token = generate(inputs, max_tokens=10)\n",
    "print(token)"
   ],
   "id": "1bbfa42d1b0a7e3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fence and ran to the other side of the fence\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:25:33.340985Z",
     "start_time": "2025-03-04T14:25:33.339203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n"
   ],
   "id": "ca7a91e4c2989fc7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:25:35.983769Z",
     "start_time": "2025-03-04T14:25:35.981217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pad on the left so we can append new tokens on the right\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\""
   ],
   "id": "db47bb08d858649b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:31:19.086915Z",
     "start_time": "2025-03-04T14:31:19.078329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# multiple prompts of varying lengths to send to the model at once\n",
    "prompts = [\n",
    "    \"The quick brown fox jumped over the\",\n",
    "    \"The rain in Spain falls\",\n",
    "    \"What comes up must\",\n",
    "]\n",
    "\n",
    "# note: padding=True ensures the padding token\n",
    "# will be inserted into the tokenized tensors\n",
    "inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")"
   ],
   "id": "148f4ac15f3b64ad",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:31:19.507752Z",
     "start_time": "2025-03-04T14:31:19.504818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"input_ids:\", inputs[\"input_ids\"])\n",
    "print(\"shape:\", inputs[\"input_ids\"].shape)"
   ],
   "id": "4f6fc385fc7ed525",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: tensor([[  464,  2068,  7586, 21831, 11687,   625,   262],\n",
      "        [50256, 50256,   464,  6290,   287,  8602,  8953],\n",
      "        [50256, 50256, 50256,  2061,  2058,   510,  1276]])\n",
      "shape: torch.Size([3, 7])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:31:43.775132Z",
     "start_time": "2025-03-04T14:31:43.769916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"attention_mask:\", inputs[\"attention_mask\"])\n",
    "print(\"shape:\", inputs[\"attention_mask\"].shape)\n"
   ],
   "id": "c43a29d3326c68f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1]])\n",
      "shape: torch.Size([3, 7])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6db9c6aef164c73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
