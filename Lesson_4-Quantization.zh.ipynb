{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:11.345759Z",
     "start_time": "2025-03-11T14:22:08.711570Z"
    }
   },
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "from helpers import generate"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.122944Z",
     "start_time": "2025-03-11T14:22:11.348631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ],
   "id": "b6f2018bd9204fd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.179622Z",
     "start_time": "2025-03-11T14:22:42.177324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define PAD token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# pad on the left so we can append new tokens on the right\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\""
   ],
   "id": "8d67d28f65efc477",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.197168Z",
     "start_time": "2025-03-11T14:22:42.195073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fix dtype post quantization to \"pretend\" to be fp32\n",
    "def get_float32_dtype(self):\n",
    "    return torch.float32\n",
    "GPT2Model.dtype = property(get_float32_dtype)\n"
   ],
   "id": "27403c3731e23f35",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.215719Z",
     "start_time": "2025-03-11T14:22:42.212318Z"
    }
   },
   "cell_type": "code",
   "source": "model.get_memory_footprint()",
   "id": "89e42f6e98908db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510342192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.255378Z",
     "start_time": "2025-03-11T14:22:42.253248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def quantize(t):\n",
    "    # obtain range of values in the tensor to map between 0 and 255\n",
    "    min_val, max_val = t.min(), t.max()\n",
    "\n",
    "    # determine the \"zero-point\", or value in the tensor to map to 0\n",
    "    scale = (max_val - min_val) / 255\n",
    "    zero_point = min_val\n",
    "\n",
    "    # quantize and clamp to ensure we're in [0, 255]\n",
    "    t_quant = (t - zero_point) / scale\n",
    "    t_quant = torch.clamp(t_quant, min=0, max=255)\n",
    "\n",
    "    # keep track of scale and zero_point for reversing quantization\n",
    "    state = (scale, zero_point)\n",
    "\n",
    "    # cast to uint8 and return\n",
    "    t_quant = t_quant.type(torch.uint8)\n",
    "    return t_quant, state"
   ],
   "id": "480893e0ba07aa16",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.265466Z",
     "start_time": "2025-03-11T14:22:42.261943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t = model.transformer.h[0].attn.c_attn.weight.data\n",
    "print(t, t.shape)"
   ],
   "id": "1ae4aef6b3381678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4738, -0.2614, -0.0978,  ...,  0.0513, -0.0584,  0.0250],\n",
      "        [ 0.0874,  0.1473,  0.2387,  ..., -0.0525, -0.0113, -0.0156],\n",
      "        [ 0.0039,  0.0695,  0.3668,  ...,  0.1143,  0.0363, -0.0318],\n",
      "        ...,\n",
      "        [-0.2592, -0.0164,  0.1991,  ...,  0.0095, -0.0516,  0.0319],\n",
      "        [ 0.1517,  0.2170,  0.1043,  ...,  0.0293, -0.0429, -0.0475],\n",
      "        [-0.4100, -0.1924, -0.2400,  ..., -0.0046,  0.0070,  0.0198]]) torch.Size([768, 2304])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.289106Z",
     "start_time": "2025-03-11T14:22:42.276138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_q, state = quantize(t)\n",
    "print(t_q, t_q.min(), t_q.max())"
   ],
   "id": "bab8367888de74c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[107, 116, 124,  ..., 130, 125, 129],\n",
      "        [132, 135, 139,  ..., 126, 128, 127],\n",
      "        [128, 131, 145,  ..., 133, 130, 127],\n",
      "        ...,\n",
      "        [116, 127, 137,  ..., 129, 126, 130],\n",
      "        [135, 138, 133,  ..., 129, 126, 126],\n",
      "        [110, 119, 117,  ..., 128, 128, 129]], dtype=torch.uint8) tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.298232Z",
     "start_time": "2025-03-11T14:22:42.296442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dequantize(t, state):\n",
    "    scale, zero_point = state\n",
    "    return t.to(torch.float32) * scale + zero_point"
   ],
   "id": "b6e12389320d11b6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.310541Z",
     "start_time": "2025-03-11T14:22:42.305446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_rev = dequantize(t_q, state)\n",
    "print(t_rev)"
   ],
   "id": "10432bfbfe285c7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4774, -0.2783, -0.1014,  ...,  0.0313, -0.0793,  0.0092],\n",
      "        [ 0.0755,  0.1419,  0.2303,  ..., -0.0572, -0.0129, -0.0351],\n",
      "        [-0.0129,  0.0534,  0.3630,  ...,  0.0976,  0.0313, -0.0351],\n",
      "        ...,\n",
      "        [-0.2783, -0.0351,  0.1861,  ...,  0.0092, -0.0572,  0.0313],\n",
      "        [ 0.1419,  0.2082,  0.0976,  ...,  0.0092, -0.0572, -0.0572],\n",
      "        [-0.4110, -0.2120, -0.2562,  ..., -0.0129, -0.0129,  0.0092]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:42.335559Z",
     "start_time": "2025-03-11T14:22:42.331720Z"
    }
   },
   "cell_type": "code",
   "source": "torch.abs(t - t_rev)",
   "id": "6782ff852dc41dee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0035, 0.0170, 0.0036,  ..., 0.0200, 0.0209, 0.0158],\n",
       "        [0.0119, 0.0055, 0.0084,  ..., 0.0046, 0.0017, 0.0195],\n",
       "        [0.0168, 0.0161, 0.0038,  ..., 0.0167, 0.0050, 0.0032],\n",
       "        ...,\n",
       "        [0.0191, 0.0187, 0.0131,  ..., 0.0004, 0.0056, 0.0006],\n",
       "        [0.0098, 0.0088, 0.0067,  ..., 0.0202, 0.0143, 0.0097],\n",
       "        [0.0010, 0.0196, 0.0162,  ..., 0.0084, 0.0199, 0.0107]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:43.231516Z",
     "start_time": "2025-03-11T14:22:42.853432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_expected = generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    [(\"The quick brown fox jumped over the\", 10)]\n",
    ")[0]\n",
    "response_expected"
   ],
   "id": "e1e49eb003e6459c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fence and ran of the fence and ran of the'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:43.270456Z",
     "start_time": "2025-03-11T14:22:43.268609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def quantize_model(model):\n",
    "    states = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "        param.data, state = quantize(param.data)\n",
    "        states[name] = state\n",
    "    return model, states\n",
    "\n",
    "\n"
   ],
   "id": "ae67fd6ff350201c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:43.530378Z",
     "start_time": "2025-03-11T14:22:43.273180Z"
    }
   },
   "cell_type": "code",
   "source": "quant_model, states = quantize_model(model)",
   "id": "1f93a1df7674a129",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:43.768638Z",
     "start_time": "2025-03-11T14:22:43.766233Z"
    }
   },
   "cell_type": "code",
   "source": "quant_model.get_memory_footprint()",
   "id": "23047bbb49b5d2a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137022768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:43.948795Z",
     "start_time": "2025-03-11T14:22:43.932067Z"
    }
   },
   "cell_type": "code",
   "source": "states",
   "id": "b853bf34ff431527",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer.wte.weight': (tensor(0.0120), tensor(-1.2698)),\n",
       " 'transformer.wpe.weight': (tensor(0.0337), tensor(-4.5381)),\n",
       " 'transformer.h.0.ln_1.weight': (tensor(0.0008), tensor(0.0419)),\n",
       " 'transformer.h.0.ln_1.bias': (tensor(0.0018), tensor(-0.2589)),\n",
       " 'transformer.h.0.attn.c_attn.weight': (tensor(0.0221), tensor(-2.8436)),\n",
       " 'transformer.h.0.attn.c_attn.bias': (tensor(0.0099), tensor(-1.3371)),\n",
       " 'transformer.h.0.attn.c_proj.weight': (tensor(0.0250), tensor(-3.3171)),\n",
       " 'transformer.h.0.attn.c_proj.bias': (tensor(0.0185), tensor(-2.6844)),\n",
       " 'transformer.h.0.ln_2.weight': (tensor(0.0057), tensor(0.0453)),\n",
       " 'transformer.h.0.ln_2.bias': (tensor(0.0055), tensor(-0.6648)),\n",
       " 'transformer.h.0.mlp.c_fc.weight': (tensor(0.0271), tensor(-2.3131)),\n",
       " 'transformer.h.0.mlp.c_fc.bias': (tensor(0.0042), tensor(-0.7462)),\n",
       " 'transformer.h.0.mlp.c_proj.weight': (tensor(0.0479), tensor(-6.1433)),\n",
       " 'transformer.h.0.mlp.c_proj.bias': (tensor(0.0098), tensor(-1.0288)),\n",
       " 'transformer.h.1.ln_1.weight': (tensor(0.0023), tensor(0.0725)),\n",
       " 'transformer.h.1.ln_1.bias': (tensor(0.0047), tensor(-0.6645)),\n",
       " 'transformer.h.1.attn.c_attn.weight': (tensor(0.0091), tensor(-1.0771)),\n",
       " 'transformer.h.1.attn.c_attn.bias': (tensor(0.0147), tensor(-1.8151)),\n",
       " 'transformer.h.1.attn.c_proj.weight': (tensor(0.0342), tensor(-4.7262)),\n",
       " 'transformer.h.1.attn.c_proj.bias': (tensor(0.0070), tensor(-0.5346)),\n",
       " 'transformer.h.1.ln_2.weight': (tensor(0.0016), tensor(0.0560)),\n",
       " 'transformer.h.1.ln_2.bias': (tensor(0.0041), tensor(-0.5866)),\n",
       " 'transformer.h.1.mlp.c_fc.weight': (tensor(0.0163), tensor(-1.8728)),\n",
       " 'transformer.h.1.mlp.c_fc.bias': (tensor(0.0036), tensor(-0.6563)),\n",
       " 'transformer.h.1.mlp.c_proj.weight': (tensor(0.0732), tensor(-4.9305)),\n",
       " 'transformer.h.1.mlp.c_proj.bias': (tensor(0.0090), tensor(-0.6991)),\n",
       " 'transformer.h.2.ln_1.weight': (tensor(0.0035), tensor(0.0460)),\n",
       " 'transformer.h.2.ln_1.bias': (tensor(0.0065), tensor(-0.5625)),\n",
       " 'transformer.h.2.attn.c_attn.weight': (tensor(0.0128), tensor(-1.6774)),\n",
       " 'transformer.h.2.attn.c_attn.bias': (tensor(0.0104), tensor(-1.4630)),\n",
       " 'transformer.h.2.attn.c_proj.weight': (tensor(0.0177), tensor(-2.2955)),\n",
       " 'transformer.h.2.attn.c_proj.bias': (tensor(0.0039), tensor(-0.4775)),\n",
       " 'transformer.h.2.ln_2.weight': (tensor(0.0027), tensor(0.0421)),\n",
       " 'transformer.h.2.ln_2.bias': (tensor(0.0040), tensor(-0.6470)),\n",
       " 'transformer.h.2.mlp.c_fc.weight': (tensor(0.0644), tensor(-5.8740)),\n",
       " 'transformer.h.2.mlp.c_fc.bias': (tensor(0.0094), tensor(-0.6598)),\n",
       " 'transformer.h.2.mlp.c_proj.weight': (tensor(0.0704), tensor(-2.8738)),\n",
       " 'transformer.h.2.mlp.c_proj.bias': (tensor(0.0079), tensor(-0.4528)),\n",
       " 'transformer.h.3.ln_1.weight': (tensor(0.0028), tensor(0.0565)),\n",
       " 'transformer.h.3.ln_1.bias': (tensor(0.0085), tensor(-0.4335)),\n",
       " 'transformer.h.3.attn.c_attn.weight': (tensor(0.0142), tensor(-1.7154)),\n",
       " 'transformer.h.3.attn.c_attn.bias': (tensor(0.0054), tensor(-0.6688)),\n",
       " 'transformer.h.3.attn.c_proj.weight': (tensor(0.0130), tensor(-2.0938)),\n",
       " 'transformer.h.3.attn.c_proj.bias': (tensor(0.0061), tensor(-1.0272)),\n",
       " 'transformer.h.3.ln_2.weight': (tensor(0.0046), tensor(-0.0003)),\n",
       " 'transformer.h.3.ln_2.bias': (tensor(0.0034), tensor(-0.4375)),\n",
       " 'transformer.h.3.mlp.c_fc.weight': (tensor(0.0193), tensor(-2.6437)),\n",
       " 'transformer.h.3.mlp.c_fc.bias': (tensor(0.0068), tensor(-1.2262)),\n",
       " 'transformer.h.3.mlp.c_proj.weight': (tensor(0.0833), tensor(-4.1391)),\n",
       " 'transformer.h.3.mlp.c_proj.bias': (tensor(0.0099), tensor(-0.6661)),\n",
       " 'transformer.h.4.ln_1.weight': (tensor(0.0024), tensor(0.0580)),\n",
       " 'transformer.h.4.ln_1.bias': (tensor(0.0082), tensor(-0.5446)),\n",
       " 'transformer.h.4.attn.c_attn.weight': (tensor(0.0252), tensor(-3.3341)),\n",
       " 'transformer.h.4.attn.c_attn.bias': (tensor(0.0210), tensor(-2.6123)),\n",
       " 'transformer.h.4.attn.c_proj.weight': (tensor(0.0144), tensor(-1.8388)),\n",
       " 'transformer.h.4.attn.c_proj.bias': (tensor(0.0045), tensor(-0.6430)),\n",
       " 'transformer.h.4.ln_2.weight': (tensor(0.0042), tensor(0.0701)),\n",
       " 'transformer.h.4.ln_2.bias': (tensor(0.0011), tensor(-0.1421)),\n",
       " 'transformer.h.4.mlp.c_fc.weight': (tensor(0.0164), tensor(-2.1614)),\n",
       " 'transformer.h.4.mlp.c_fc.bias': (tensor(0.0047), tensor(-0.4530)),\n",
       " 'transformer.h.4.mlp.c_proj.weight': (tensor(0.0334), tensor(-3.7426)),\n",
       " 'transformer.h.4.mlp.c_proj.bias': (tensor(0.0088), tensor(-0.6683)),\n",
       " 'transformer.h.5.ln_1.weight': (tensor(0.0027), tensor(0.0864)),\n",
       " 'transformer.h.5.ln_1.bias': (tensor(0.0060), tensor(-0.4506)),\n",
       " 'transformer.h.5.attn.c_attn.weight': (tensor(0.0107), tensor(-1.3924)),\n",
       " 'transformer.h.5.attn.c_attn.bias': (tensor(0.0041), tensor(-0.5594)),\n",
       " 'transformer.h.5.attn.c_proj.weight': (tensor(0.0144), tensor(-1.9833)),\n",
       " 'transformer.h.5.attn.c_proj.bias': (tensor(0.0051), tensor(-0.7030)),\n",
       " 'transformer.h.5.ln_2.weight': (tensor(0.0054), tensor(0.0428)),\n",
       " 'transformer.h.5.ln_2.bias': (tensor(0.0024), tensor(-0.3045)),\n",
       " 'transformer.h.5.mlp.c_fc.weight': (tensor(0.0146), tensor(-1.9646)),\n",
       " 'transformer.h.5.mlp.c_fc.bias': (tensor(0.0043), tensor(-0.4335)),\n",
       " 'transformer.h.5.mlp.c_proj.weight': (tensor(0.0219), tensor(-2.8407)),\n",
       " 'transformer.h.5.mlp.c_proj.bias': (tensor(0.0077), tensor(-0.7120)),\n",
       " 'transformer.h.6.ln_1.weight': (tensor(0.0028), tensor(0.0637)),\n",
       " 'transformer.h.6.ln_1.bias': (tensor(0.0085), tensor(-0.6354)),\n",
       " 'transformer.h.6.attn.c_attn.weight': (tensor(0.0118), tensor(-1.3877)),\n",
       " 'transformer.h.6.attn.c_attn.bias': (tensor(0.0060), tensor(-0.8114)),\n",
       " 'transformer.h.6.attn.c_proj.weight': (tensor(0.0140), tensor(-1.7240)),\n",
       " 'transformer.h.6.attn.c_proj.bias': (tensor(0.0028), tensor(-0.3124)),\n",
       " 'transformer.h.6.ln_2.weight': (tensor(0.0051), tensor(0.0424)),\n",
       " 'transformer.h.6.ln_2.bias': (tensor(0.0028), tensor(-0.2726)),\n",
       " 'transformer.h.6.mlp.c_fc.weight': (tensor(0.0132), tensor(-1.2295)),\n",
       " 'transformer.h.6.mlp.c_fc.bias': (tensor(0.0044), tensor(-0.4310)),\n",
       " 'transformer.h.6.mlp.c_proj.weight': (tensor(0.0197), tensor(-2.2441)),\n",
       " 'transformer.h.6.mlp.c_proj.bias': (tensor(0.0068), tensor(-0.6757)),\n",
       " 'transformer.h.7.ln_1.weight': (tensor(0.0029), tensor(0.0746)),\n",
       " 'transformer.h.7.ln_1.bias': (tensor(0.0078), tensor(-0.7903)),\n",
       " 'transformer.h.7.attn.c_attn.weight': (tensor(0.0137), tensor(-1.6830)),\n",
       " 'transformer.h.7.attn.c_attn.bias': (tensor(0.0058), tensor(-0.7567)),\n",
       " 'transformer.h.7.attn.c_proj.weight': (tensor(0.0163), tensor(-2.2344)),\n",
       " 'transformer.h.7.attn.c_proj.bias': (tensor(0.0038), tensor(-0.4598)),\n",
       " 'transformer.h.7.ln_2.weight': (tensor(0.0050), tensor(0.0149)),\n",
       " 'transformer.h.7.ln_2.bias': (tensor(0.0043), tensor(-0.4666)),\n",
       " 'transformer.h.7.mlp.c_fc.weight': (tensor(0.0082), tensor(-0.8502)),\n",
       " 'transformer.h.7.mlp.c_fc.bias': (tensor(0.0061), tensor(-0.7277)),\n",
       " 'transformer.h.7.mlp.c_proj.weight': (tensor(0.0346), tensor(-4.5328)),\n",
       " 'transformer.h.7.mlp.c_proj.bias': (tensor(0.0075), tensor(-0.7256)),\n",
       " 'transformer.h.8.ln_1.weight': (tensor(0.0034), tensor(0.0657)),\n",
       " 'transformer.h.8.ln_1.bias': (tensor(0.0093), tensor(-0.9212)),\n",
       " 'transformer.h.8.attn.c_attn.weight': (tensor(0.0144), tensor(-1.7242)),\n",
       " 'transformer.h.8.attn.c_attn.bias': (tensor(0.0067), tensor(-0.8690)),\n",
       " 'transformer.h.8.attn.c_proj.weight': (tensor(0.0201), tensor(-2.1775)),\n",
       " 'transformer.h.8.attn.c_proj.bias': (tensor(0.0064), tensor(-0.4676)),\n",
       " 'transformer.h.8.ln_2.weight': (tensor(0.0041), tensor(0.0180)),\n",
       " 'transformer.h.8.ln_2.bias': (tensor(0.0045), tensor(-0.6950)),\n",
       " 'transformer.h.8.mlp.c_fc.weight': (tensor(0.0105), tensor(-1.2222)),\n",
       " 'transformer.h.8.mlp.c_fc.bias': (tensor(0.0060), tensor(-0.5317)),\n",
       " 'transformer.h.8.mlp.c_proj.weight': (tensor(0.0354), tensor(-3.6508)),\n",
       " 'transformer.h.8.mlp.c_proj.bias': (tensor(0.0080), tensor(-0.8268)),\n",
       " 'transformer.h.9.ln_1.weight': (tensor(0.0034), tensor(0.0696)),\n",
       " 'transformer.h.9.ln_1.bias': (tensor(0.0088), tensor(-0.9785)),\n",
       " 'transformer.h.9.attn.c_attn.weight': (tensor(0.0148), tensor(-1.7891)),\n",
       " 'transformer.h.9.attn.c_attn.bias': (tensor(0.0072), tensor(-1.0424)),\n",
       " 'transformer.h.9.attn.c_proj.weight': (tensor(0.0143), tensor(-1.6596)),\n",
       " 'transformer.h.9.attn.c_proj.bias': (tensor(0.0112), tensor(-0.9575)),\n",
       " 'transformer.h.9.ln_2.weight': (tensor(0.0036), tensor(0.0177)),\n",
       " 'transformer.h.9.ln_2.bias': (tensor(0.0042), tensor(-0.5610)),\n",
       " 'transformer.h.9.mlp.c_fc.weight': (tensor(0.0192), tensor(-2.7818)),\n",
       " 'transformer.h.9.mlp.c_fc.bias': (tensor(0.0043), tensor(-0.4776)),\n",
       " 'transformer.h.9.mlp.c_proj.weight': (tensor(0.0406), tensor(-5.4875)),\n",
       " 'transformer.h.9.mlp.c_proj.bias': (tensor(0.0109), tensor(-1.2830)),\n",
       " 'transformer.h.10.ln_1.weight': (tensor(0.0033), tensor(0.0751)),\n",
       " 'transformer.h.10.ln_1.bias': (tensor(0.0068), tensor(-0.6528)),\n",
       " 'transformer.h.10.attn.c_attn.weight': (tensor(0.0145), tensor(-1.8938)),\n",
       " 'transformer.h.10.attn.c_attn.bias': (tensor(0.0066), tensor(-0.9162)),\n",
       " 'transformer.h.10.attn.c_proj.weight': (tensor(0.0325), tensor(-4.0754)),\n",
       " 'transformer.h.10.attn.c_proj.bias': (tensor(0.0268), tensor(-2.9879)),\n",
       " 'transformer.h.10.ln_2.weight': (tensor(0.0042), tensor(0.0201)),\n",
       " 'transformer.h.10.ln_2.bias': (tensor(0.0051), tensor(-0.6005)),\n",
       " 'transformer.h.10.mlp.c_fc.weight': (tensor(0.0184), tensor(-2.5535)),\n",
       " 'transformer.h.10.mlp.c_fc.bias': (tensor(0.0070), tensor(-1.0728)),\n",
       " 'transformer.h.10.mlp.c_proj.weight': (tensor(0.0798), tensor(-11.0504)),\n",
       " 'transformer.h.10.mlp.c_proj.bias': (tensor(0.0095), tensor(-1.0768)),\n",
       " 'transformer.h.11.ln_1.weight': (tensor(0.0033), tensor(0.1061)),\n",
       " 'transformer.h.11.ln_1.bias': (tensor(0.0052), tensor(-0.3304)),\n",
       " 'transformer.h.11.attn.c_attn.weight': (tensor(0.0179), tensor(-2.2638)),\n",
       " 'transformer.h.11.attn.c_attn.bias': (tensor(0.0055), tensor(-0.8046)),\n",
       " 'transformer.h.11.attn.c_proj.weight': (tensor(0.0690), tensor(-8.8818)),\n",
       " 'transformer.h.11.attn.c_proj.bias': (tensor(0.0353), tensor(-5.3729)),\n",
       " 'transformer.h.11.ln_2.weight': (tensor(0.0047), tensor(0.0278)),\n",
       " 'transformer.h.11.ln_2.bias': (tensor(0.0025), tensor(-0.2093)),\n",
       " 'transformer.h.11.mlp.c_fc.weight': (tensor(0.0143), tensor(-1.9649)),\n",
       " 'transformer.h.11.mlp.c_fc.bias': (tensor(0.0068), tensor(-1.2082)),\n",
       " 'transformer.h.11.mlp.c_proj.weight': (tensor(0.0720), tensor(-9.2115)),\n",
       " 'transformer.h.11.mlp.c_proj.bias': (tensor(0.0032), tensor(-0.3835)),\n",
       " 'transformer.ln_f.weight': (tensor(0.0683), tensor(0.0044)),\n",
       " 'transformer.ln_f.bias': (tensor(0.0453), tensor(-4.1918))}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:43.958842Z",
     "start_time": "2025-03-11T14:22:43.957495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def size_in_bytes(t):\n",
    "    return t.numel() * t.element_size()\n",
    "\n"
   ],
   "id": "7e59b94a4f9c24c9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:43.969567Z",
     "start_time": "2025-03-11T14:22:43.967331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sum([\n",
    "    size_in_bytes(v[0]) + size_in_bytes(v[1])\n",
    "    for v in states.values()\n",
    "])"
   ],
   "id": "294823d36463d261",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:43.979352Z",
     "start_time": "2025-03-11T14:22:43.977860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dequantize_model(model, states):\n",
    "    for name, param in model.named_parameters():\n",
    "        param.data = dequantize(param.data, states[name])\n",
    "    return model"
   ],
   "id": "ef3be6d120320c42",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:44.105239Z",
     "start_time": "2025-03-11T14:22:43.994151Z"
    }
   },
   "cell_type": "code",
   "source": "dequant_model = dequantize_model(quant_model, states)",
   "id": "1ec99d3b318715e2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:44.110801Z",
     "start_time": "2025-03-11T14:22:44.108432Z"
    }
   },
   "cell_type": "code",
   "source": "dequant_model.get_memory_footprint()",
   "id": "fc863b6b4604a8f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510342192"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:44.386710Z",
     "start_time": "2025-03-11T14:22:44.120579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_expected = generate(\n",
    "    dequant_model,\n",
    "    tokenizer,\n",
    "    [(\"The quick brown fox jumped over the\", 10)]\n",
    "\n",
    ")[0]\n",
    "response_expected"
   ],
   "id": "3c2a0544900448af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fence.\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:22:44.397627Z",
     "start_time": "2025-03-11T14:22:44.396367Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "745975bb637862e7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
